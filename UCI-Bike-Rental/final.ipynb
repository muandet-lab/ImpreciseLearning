{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dfdbc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.8/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.8/site-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.22.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.8/site-packages (from seaborn) (1.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.33.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (8.3.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (59.5.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.29)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.12.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: SciencePlots in /opt/conda/lib/python3.8/site-packages (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from SciencePlots) (3.5.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->SciencePlots) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->SciencePlots) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->SciencePlots) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->SciencePlots) (4.33.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->SciencePlots) (3.0.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->SciencePlots) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from matplotlib->SciencePlots) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->SciencePlots) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->SciencePlots) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "!pip install ipywidgets\n",
    "!pip install SciencePlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8806b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from data import data_generator\n",
    "from iro import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#%matplotlib notebook\n",
    "random_seed = 0\n",
    "np.random.seed(seed=random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081bcd84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Architecture\n",
    "class BikeSharingModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BikeSharingModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 1)\n",
    "        self.relu = nn.PReLU()\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop(self.relu(self.fc1(x)))\n",
    "        x = self.drop(self.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87a2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hypernetwork\n",
    "class FHatNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        super(FHatNetwork, self).__init__()\n",
    "        layers = []\n",
    "        if hidden_sizes == []:\n",
    "            self.model = nn.Linear(input_size, output_size)\n",
    "        else:\n",
    "            layers.append(nn.Linear(input_size, hidden_sizes[0]))\n",
    "            layers.append(nn.PReLU())\n",
    "            for i in range(1, len(hidden_sizes)):\n",
    "                layers.append(nn.Linear(hidden_sizes[i - 1], hidden_sizes[i]))\n",
    "                layers.append(nn.PReLU())\n",
    "            layers.append(nn.Linear(hidden_sizes[-1], output_size))\n",
    "            self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class HyperNetwork(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HyperNetwork, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hyper_layer = FHatNetwork(1,[],input_dim)\n",
    "    def forward(self, x, alpha):\n",
    "        alpha = alpha.view(1,1)\n",
    "        beta = torch.tanh(self.hyper_layer(alpha))\n",
    "        return x@beta.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "296945cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def fixed(data_dict_train, data_dict_test, dim, alphas):\n",
    "    h_pareto = HyperNetwork(dim).to(device)\n",
    "    ARM_Regression(name=\"cvar-full\").fit_h_pareto(h_pareto, data_dict_train)\n",
    "    print(\"Pareto Trained\")\n",
    "    \n",
    "    h_inf = HyperNetwork(dim).to(device)\n",
    "    ARM_Regression(name=\"cvar-full\").fit_h(h_inf, data_dict_train, 1,1)\n",
    "    print(\"Beta 1 1 Trained\")\n",
    "    \n",
    "    \n",
    "    f = HyperNetwork(dim).to(device)\n",
    "    groundtruths = []\n",
    "    for alpha in alphas:\n",
    "        ARM_Regression(name=\"cvar-full\").fit_h_as_f(f, data_dict_train, alpha)\n",
    "        groundtruths.append(copy.deepcopy(f))\n",
    "        \n",
    "    return groundtruths, [h_inf, h_pareto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0f809f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_generator()\n",
    "data_dict_train, data_dict_test = data.env_dict_train, data.env_dict_test\n",
    "dim = data_dict_train['0']['x'].shape[1]\n",
    "rho=\"cvar\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b7c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(true_alpha, model, data_dict_test):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        train_risks = []\n",
    "        for e in data_dict_test.keys():\n",
    "            x, y = data_dict_test[e]['x'].to(device), data_dict_test[e]['y'].to(device)\n",
    "            train_risks.append(loss_fn(model(x, torch.tensor(true_alpha).to(device)), y)) \n",
    "        train_risks = torch.stack(train_risks)\n",
    "    cvar = aggregation_function(name=\"cvar-full\").aggregate(train_risks, true_alpha)\n",
    "    return cvar.cpu()\n",
    "def execute_gt(true_alpha, model, data_dict_test):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        train_risks = []\n",
    "        for e in data_dict_test.keys():\n",
    "            x, y = data_dict_test[e]['x'].to(device), data_dict_test[e]['y'].to(device)\n",
    "            train_risks.append(loss_fn(model(x), y)) \n",
    "        train_risks = torch.stack(train_risks)\n",
    "    cvar = aggregation_function(name=\"cvar-full\").aggregate(train_risks, true_alpha)\n",
    "    return cvar.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c61f316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 5.2021026611328125\n",
      "Epoch [2/30], Loss: 3.593947172164917\n",
      "Epoch [3/30], Loss: 2.804157257080078\n",
      "Epoch [4/30], Loss: 3.010921001434326\n",
      "Epoch [5/30], Loss: 2.0124378204345703\n",
      "Epoch [6/30], Loss: 1.9722667932510376\n",
      "Epoch [7/30], Loss: 1.760371446609497\n",
      "Epoch [8/30], Loss: 1.4184045791625977\n",
      "Epoch [9/30], Loss: 1.3351962566375732\n",
      "Epoch [10/30], Loss: 1.2788171768188477\n",
      "Epoch [11/30], Loss: 1.2254139184951782\n",
      "Epoch [12/30], Loss: 1.1041803359985352\n",
      "Epoch [13/30], Loss: 1.0179173946380615\n",
      "Epoch [14/30], Loss: 0.9034579992294312\n",
      "Epoch [15/30], Loss: 0.9518740773200989\n",
      "Epoch [16/30], Loss: 0.8824483752250671\n",
      "Epoch [17/30], Loss: 0.6793698072433472\n",
      "Epoch [18/30], Loss: 0.6364538669586182\n",
      "Epoch [19/30], Loss: 0.5828886032104492\n",
      "Epoch [20/30], Loss: 0.5755199193954468\n",
      "Epoch [21/30], Loss: 0.5959621071815491\n",
      "Epoch [22/30], Loss: 0.6174756288528442\n",
      "Epoch [23/30], Loss: 0.6319419741630554\n",
      "Epoch [24/30], Loss: 0.5656282305717468\n",
      "Epoch [25/30], Loss: 0.5708616375923157\n",
      "Epoch [26/30], Loss: 0.6038674116134644\n",
      "Epoch [27/30], Loss: 0.6026837229728699\n",
      "Epoch [28/30], Loss: 0.6127130389213562\n",
      "Epoch [29/30], Loss: 0.6655640602111816\n",
      "Epoch [30/30], Loss: 0.5767034292221069\n",
      "Pareto Trained\n",
      "Epoch [10/30], Loss: 1.2410045862197876\n",
      "Epoch [20/30], Loss: 0.7254285216331482\n",
      "Epoch [30/30], Loss: 0.5099839568138123\n",
      "Beta 1 1 Trained\n",
      "Epoch [100/100], Loss: 0.2758508026599884\n",
      "Epoch [100/100], Loss: 0.3223154544830322\n",
      "Epoch [100/100], Loss: 0.34613198041915894\n",
      "Epoch [100/100], Loss: 0.40724635124206543\n",
      "Epoch [100/100], Loss: 0.4084286093711853\n",
      "Epoch [100/100], Loss: 0.4805299639701843\n",
      "Epoch [100/100], Loss: 0.5280361175537109\n",
      "Epoch [1/30], Loss: 4.188300132751465\n",
      "Epoch [2/30], Loss: 2.9464151859283447\n",
      "Epoch [3/30], Loss: 2.4962007999420166\n",
      "Epoch [4/30], Loss: 2.2493655681610107\n",
      "Epoch [5/30], Loss: 1.9098424911499023\n",
      "Epoch [6/30], Loss: 1.4151909351348877\n",
      "Epoch [7/30], Loss: 1.4097821712493896\n",
      "Epoch [8/30], Loss: 1.519283652305603\n",
      "Epoch [9/30], Loss: 1.5368248224258423\n",
      "Epoch [10/30], Loss: 2.040905714035034\n",
      "Epoch [11/30], Loss: 2.5782322883605957\n",
      "Epoch [12/30], Loss: 1.437281847000122\n",
      "Epoch [13/30], Loss: 1.292518138885498\n",
      "Epoch [14/30], Loss: 0.9340302348136902\n",
      "Epoch [15/30], Loss: 0.83246248960495\n",
      "Epoch [16/30], Loss: 0.7102712392807007\n",
      "Epoch [17/30], Loss: 0.9283469915390015\n",
      "Epoch [18/30], Loss: 0.8346337080001831\n",
      "Epoch [19/30], Loss: 0.8642576336860657\n",
      "Epoch [20/30], Loss: 0.701504111289978\n",
      "Epoch [21/30], Loss: 0.6394741535186768\n",
      "Epoch [22/30], Loss: 0.8017193078994751\n",
      "Epoch [23/30], Loss: 0.8354116678237915\n",
      "Epoch [24/30], Loss: 0.9456982612609863\n",
      "Epoch [25/30], Loss: 0.9582617878913879\n",
      "Epoch [26/30], Loss: 0.7727723121643066\n",
      "Epoch [27/30], Loss: 0.757610559463501\n",
      "Epoch [28/30], Loss: 0.6003884673118591\n",
      "Epoch [29/30], Loss: 0.7013007402420044\n",
      "Epoch [30/30], Loss: 0.6625363230705261\n",
      "Pareto Trained\n",
      "Epoch [10/30], Loss: 1.5836063623428345\n",
      "Epoch [20/30], Loss: 1.2000970840454102\n",
      "Epoch [30/30], Loss: 0.8921300172805786\n",
      "Beta 1 1 Trained\n",
      "Epoch [100/100], Loss: 0.2761344611644745\n",
      "Epoch [100/100], Loss: 0.3238896131515503\n",
      "Epoch [100/100], Loss: 0.3492284417152405\n",
      "Epoch [100/100], Loss: 0.38562247157096863\n",
      "Epoch [100/100], Loss: 0.398790568113327\n",
      "Epoch [100/100], Loss: 0.4056236147880554\n",
      "Epoch [100/100], Loss: 0.4161825180053711\n",
      "Epoch [1/30], Loss: 12.740028381347656\n",
      "Epoch [2/30], Loss: 6.567683219909668\n",
      "Epoch [3/30], Loss: 4.154353618621826\n",
      "Epoch [4/30], Loss: 2.9284470081329346\n",
      "Epoch [5/30], Loss: 3.6387572288513184\n",
      "Epoch [6/30], Loss: 2.954329013824463\n",
      "Epoch [7/30], Loss: 3.275036334991455\n",
      "Epoch [8/30], Loss: 2.9234962463378906\n",
      "Epoch [9/30], Loss: 4.091093063354492\n",
      "Epoch [10/30], Loss: 4.503210067749023\n",
      "Epoch [11/30], Loss: 4.532261848449707\n",
      "Epoch [12/30], Loss: 4.904148101806641\n",
      "Epoch [13/30], Loss: 4.326403617858887\n",
      "Epoch [14/30], Loss: 11.513143539428711\n",
      "Epoch [15/30], Loss: 6.445040702819824\n",
      "Epoch [16/30], Loss: 5.647236347198486\n",
      "Epoch [17/30], Loss: 4.754878997802734\n",
      "Epoch [18/30], Loss: 2.5328872203826904\n",
      "Epoch [19/30], Loss: 3.1000795364379883\n",
      "Epoch [20/30], Loss: 2.074164628982544\n",
      "Epoch [21/30], Loss: 2.542337417602539\n",
      "Epoch [22/30], Loss: 1.9022023677825928\n",
      "Epoch [23/30], Loss: 1.5909312963485718\n",
      "Epoch [24/30], Loss: 1.4998067617416382\n",
      "Epoch [25/30], Loss: 1.4004039764404297\n",
      "Epoch [26/30], Loss: 1.7419700622558594\n",
      "Epoch [27/30], Loss: 1.987227439880371\n",
      "Epoch [28/30], Loss: 1.7813966274261475\n",
      "Epoch [29/30], Loss: 1.9366731643676758\n",
      "Epoch [30/30], Loss: 2.2986786365509033\n",
      "Pareto Trained\n",
      "Epoch [10/30], Loss: 0.858324408531189\n",
      "Epoch [20/30], Loss: 0.5379018783569336\n",
      "Epoch [30/30], Loss: 0.45064401626586914\n",
      "Beta 1 1 Trained\n",
      "Epoch [100/100], Loss: 0.27463701367378235\n",
      "Epoch [100/100], Loss: 0.32251057028770447\n",
      "Epoch [100/100], Loss: 0.3447512090206146\n",
      "Epoch [100/100], Loss: 0.3758869469165802\n",
      "Epoch [100/100], Loss: 0.4079975485801697\n",
      "Epoch [100/100], Loss: 0.5229099988937378\n",
      "Epoch [100/100], Loss: 0.4579048156738281\n"
     ]
    }
   ],
   "source": [
    "# New function to reset seeds and reinitialize models\n",
    "def reinitialize_models(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    return fixed(data_dict_train,data_dict_train, dim, true_alphas)\n",
    "\n",
    "# Main loop for iterating over different seeds\n",
    "num_seeds = [0,1,2]  # Number of different seeds to use\n",
    "true_alphas = [0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 0.99]\n",
    "learners = [\"GT\", \"Avg\", \"Worse\", \"Inf\", \"Pareto\"]\n",
    "new_key_box = {seed:[] for seed in num_seeds}\n",
    "results = {str(true_alpha): {\"GT\": [], \"Avg\": [], \"Worse\": [], \"Inf\": [], \"Pareto\":[]} for true_alpha in true_alphas}\n",
    "regrets = {learner:copy.deepcopy(new_key_box) for learner in learners[1:]}\n",
    "for seed in num_seeds:\n",
    "    # Reinitialize models with the new seed\n",
    "    ground_truths,h_models = reinitialize_models(seed)\n",
    "    \n",
    "    for index in range(len(true_alphas)):\n",
    "        ground_truth = execute(true_alphas[index], ground_truths[index], data_dict_test)\n",
    "        avg_case = execute(true_alphas[index], ground_truths[0], data_dict_test)\n",
    "        worse_case = execute(true_alphas[index], ground_truths[-1], data_dict_test)\n",
    "        inf_unif = execute(true_alphas[index], h_models[0], data_dict_test)\n",
    "        pareto   = execute(true_alphas[index], h_models[1], data_dict_test)\n",
    "        # Collecting the results\n",
    "        results[str(true_alphas[index])][\"GT\"].append(ground_truth)\n",
    "        results[str(true_alphas[index])][\"Avg\"].append(avg_case)\n",
    "        results[str(true_alphas[index])][\"Worse\"].append(worse_case)\n",
    "        results[str(true_alphas[index])][\"Inf\"].append(inf_unif)\n",
    "        results[str(true_alphas[index])][\"Pareto\"].append(pareto)\n",
    "        \n",
    "        regrets[\"Avg\"][seed].append(avg_case.item()-ground_truth.item())\n",
    "        regrets[\"Worse\"][seed].append(worse_case.item()-ground_truth.item())\n",
    "        regrets[\"Inf\"][seed].append(inf_unif.item()-ground_truth.item())\n",
    "        regrets[\"Pareto\"][seed].append(pareto.item()-ground_truth.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c97bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Avg': 4.812979499499003, 'Worse': 0.6620331605275472, 'Inf': 0.7224142551422119, 'Pareto': 0.4294259548187256} {'Avg': 6.205005014350316, 'Worse': 0.03855799323237259, 'Inf': 0.3054380732622151, 'Pareto': 0.20054302410205138}\n"
     ]
    }
   ],
   "source": [
    "def compute_regret_stats(regrets):\n",
    "    means = {}\n",
    "    std_devs = {}\n",
    "    for learner in regrets.keys():\n",
    "        stats = []\n",
    "        for seed in regrets[learner].keys():\n",
    "            stats.append(max(regrets[learner][seed]))\n",
    "        mean, std = np.mean(stats), np.std(stats)\n",
    "        means[learner], std_devs[learner] = mean, std\n",
    "    return means, std_devs\n",
    "\n",
    "def compute_statistics(results):\n",
    "    means = {}\n",
    "    std_devs = {}\n",
    "\n",
    "    for key, value in results.items():\n",
    "        # Ensure value is a list of numbers, not a dictionary\n",
    "        if isinstance(value, dict):\n",
    "            means[key] = {sub_key: np.mean(sub_value) for sub_key, sub_value in value.items()}\n",
    "            std_devs[key] = {sub_key: np.std(sub_value) for sub_key, sub_value in value.items()}\n",
    "        else:\n",
    "            means[key] = np.mean(value)\n",
    "            std_devs[key] = np.std(value)\n",
    "\n",
    "    return means, std_devs\n",
    "means, std_devs = compute_statistics(results)\n",
    "reg_means, reg_stds = compute_regret_stats(regrets)\n",
    "print(reg_means, reg_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e6dda5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT\n",
      "0.6162 0.067100674\n",
      "0.7465 0.110736\n",
      "1.0086 0.11697672\n",
      "1.5965 0.41924062\n",
      "1.9219 0.45087922\n",
      "2.8251 0.9070179\n",
      "2.9743 0.9176269\n",
      "Avg Case\n",
      "0.6162 0.067100674\n",
      "0.8344 0.21378803\n",
      "1.3957 0.7147117\n",
      "2.4018 1.6316671\n",
      "4.0261 3.299366\n",
      "6.2942 5.615907\n",
      "7.4002 6.757144\n",
      "Worse Case\n",
      "1.277 0.035844747\n",
      "1.3414 0.011125628\n",
      "1.3547 0.07075362\n",
      "1.619 0.174331\n",
      "2.033 0.33626387\n",
      "2.6227 0.6797899\n",
      "2.9743 0.9176269\n",
      "Inf\n",
      "1.123 0.022979748\n",
      "1.1767 0.027563538\n",
      "1.1863 0.06968534\n",
      "1.3761 0.1429776\n",
      "1.7009 0.10498565\n",
      "2.2626 0.3259606\n",
      "2.4879 0.48973155\n",
      "Pareto\n",
      "0.9963 0.1732365\n",
      "1.0996 0.21895196\n",
      "1.1511 0.32479444\n",
      "1.2915 0.532627\n",
      "1.5246 0.7827878\n",
      "1.9506 1.1196239\n",
      "2.1508 1.2767332\n"
     ]
    }
   ],
   "source": [
    "print(\"GT\")\n",
    "for key in results.keys():\n",
    "    print(round(means[key]['GT'],4),std_devs[key]['GT'])\n",
    "\n",
    "print(\"Avg Case\")\n",
    "for key in results.keys():\n",
    "    print(round(means[key]['Avg'],4),std_devs[key]['Avg'])\n",
    "print(\"Worse Case\")\n",
    "for key in results.keys():\n",
    "    print(round(means[key]['Worse'],4),std_devs[key]['Worse'])\n",
    "\n",
    "print(\"Inf\")\n",
    "for key in results.keys():\n",
    "    print(round(means[key]['Inf'],4),std_devs[key]['Inf'])\n",
    "    \n",
    "print(\"Pareto\")\n",
    "for key in results.keys():\n",
    "    print(round(means[key]['Pareto'],4),std_devs[key]['Pareto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c811186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
